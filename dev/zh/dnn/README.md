# 深度学习及 KPU 基础知识

## 阅读完本章文档可以了解什么？

1. 了解深度学习一些基础内容
2. 了解 K210 内部 KPU 的特性
3. 了解 KPU 使用过程中可能会遇到的问题，以及问题的解决方法

## 概述

在本章中，将会为大家介绍深度学习和 K210 内部 KPU 的一些基础知识，以及大家在这部分容易遇到的问题。深度学习及其所涵盖的应用实例是一个非常庞大的领域，没有人能够用一篇文档就把它说得很清楚。希望这篇文档能够让大家对深度学习有一定的了解，产生超出本文档说明外的问题时，能够通过搜索引擎查询等手段解决问题。

---

## 关于深度学习

在介绍深度学习前，我们先来介绍神经网络。

​	什么是神经网络呢？是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。

下面，让我们举个简单例子来说明它干了什么。

其实从某种程度来上说，我们在上小学时，就已经开始运用神经网络的相关思想来解决实际问题了。此时的你，可能满脸问号QAQ。不怕，且听我一一道来。现在，假设有一个方程  `y = kx + b` 。相信这个方程你一定见过无数次。其实我们可以把这个方程当作神经网络的"模型"，未知数"k"当作神经网络的权重，"b"当作神经网络的偏置。此时我们要训练这个神经网络模型，其实训练的过程，就是在数据集上求解全局最优权重和偏置的过程。此时，假设这个方程满足"x=1,y=2","x=2,y=4"。这个满足条件便是上文说到的数据集，通过在人脑中，对这个网络的训练，我们可以得知整个网络的最优权重为2，最优偏置为0。此时，便完成了神经网络的训练。

不过值得提出的是，训练的最终目的，永远都是预测。古往今来，那么多神经网络消耗大量算力资源去寻找合适权重和偏置。都是为了能够寻找一个输入数据与输出数据之间的对应关系。一个优秀的神经网络，它的输入数据应该是随机的，不确定的(没有在数据集中被训练过的)。而输出数据则是准确的，可靠的。回到上文，我们训练了神经网络"y = 2x + 0"，此时数据集拥有的数据x为"1"和"2"。此时为了评估模型性能，我们输入非数据集数据"3"，此时，通过神经网络前向传播，得到了输出值"6"。至此，完成了神经网络模型的预测。

上文用了非常简单的demo来为大家阐述神经网络究竟在干啥，下面让我们一起看看真正的神经网络模型长啥样。

![全连接神经网络模型](https://i.loli.net/2020/06/30/PVxMcSde8YJ4Q9b.jpg)

上图为大家展示了一个比较常见的全连接神经网络模型(Fully connected neural network)。对比这个网络结构与之前的"y = 2x + 0"网络，我们可以发现如下不同:

1. 输入数据个数不确定(可以有n个输入)
2. 输出数据个数不确定(可以有n个输出)
3. 参数个数不确定(图中可以有n个全连接层，每个层所包含神经元可以有n个，从而导致参数个数为n)

模型的构造过程可以看作是参数个数的确定过程(当网络层结构确定后，参数个数也确定了)，模型的训练过程可以看作是在数据集上全局最优参数的确定过程。模型的预测过程可以看作是输入数据*参数 = 预测结果的过程。(*代表进行某种运算)

在对神经网络有了一定的了解后，接下来将会介绍深度学习。大家可以把深度学习当做是一种改良版的神经网络算法。它与其他几个名词之间的关系为:机器学习是人工智能的一个子集，深度学习和神经网络又是机器学习的一个子集。

神经网络和深度学习之间的区别，以及深度学习的优点等内容，由于篇幅有限，不能在此一一介绍，大家感兴趣的话，可以通过搜索引擎进行查询。

## 关于 KPU

K210 SOC 内部搭载一颗 KPU(Neural Network Processor), KPU 即通用的神经网络处理器，它可以在低功耗的情况下实现卷积神经网络计算，时时获取被检测目标的大小、坐标和种类，对人脸或者物体进行检测和分类。

K210 搭载的 KPU 具备以下几个特点：

1. 支持主流训练框架按照特定限制规则训练出来的定点化模型
2. 对网络层数无直接限制，支持每层卷积神经网络参数单独配置，包括输入输出通道数目、输入输 出行宽列高
3. 支持两种卷积内核 1x1 和 3x3
4. 支持任意形式的激活函数
5. 实时工作时最大支持神经网络参数大小为 5.5MiB 到 5.9MiB
6. 非实时工作时最大支持网络参数大小为（Flash 容量-软件体积）

KPU 的内部结构如下图所示。

![K210 KPU结构](https://i.loli.net/2020/06/30/Q9tPOjyMWFiTwxA.png)

Maixpy下 KPU 相关 API 及 Demo 可以点击[此处](https://maixpy.sipeed.com/zh/libs/Maix/kpu.html?h=kpu)查看。

## KPU使用过程中的常见问题

### 1. KPU能够加载多大的模型？

当k210运行 c 代码时，能够加载 6MB左右的模型。
当运行maixpy(mini)时，能够加载3MB左右的模型。
当运行maixpy(完整版)时，能够加载2MB左右的模型。

### 2. 什么模型能被KPU加载运行？

被nncase转换后的kmodel能够被kpu加载运行。

nncase使用说明点击[此处](https://github.com/kendryte/nncase/blob/master/docs/USAGE_ZH.md)
nncase tflite ops支持点击[此处](https://github.com/kendryte/nncase/blob/master/docs/tflite_ops.md)
nncase 常见问题点击[此处](https://github.com/kendryte/nncase/blob/master/docs/FAQ_ZH.md)

### 3. KPU能通过哪些方式加载模型？

1. 加载TF卡中的模型

   ```python
   kpu.load("/sd/test.kmodel")
   ```

2. 加载Flash中的模型

   ```python
   kpu.load(offset)
   ```

   此处的offset为模型在flash中的偏移地址，模型可以通过k-flash烧入k210内部flash中

### 4. 报错"memory overflow"怎么办？

出现这个问题，一般是由于模型过大引起的。可以依次尝试如下解决方案:

1. 更换maixpy mini版本固件
2. 进行模型剪枝优化
3. 放弃在maixpy固件下开发，而采用勘智的C SDK进行开发。

### 5. 报错"load error,only support kmodel v3/v4"怎么办？

出现这个问题可以尝试如下解决方案:

1. 如果为flash中加载模型，请确保flash offset填写正确，并保证和maixpy固件没有冲突。
2. 如果是采用nncase 0.2.0进行转换的kmodel V4，请尝试采用nncase 0.1.0进行转换，从而生成kmodel V3。（截至2020/06/30，maixpy对kmodel v4的加载bug还未修复）

### 6. 我想实现不同模型的选择加载(例如按下按钮运行目标分类，再次按下按钮则运行目标检测)，应该怎么写程序？

因为flash有限，固建议将所有k210模型放到TF卡内进行加载。因为内部RAM有限，所以当需要切换不同模型进行`kpu.load(k210model)`前，请先执行`kpu.deinit(k210model)`对SRAM中的模型进行释放。否则将会报错"memory overflow"。











